# Sources, channels, and Sinks
agent.sources = accessLogsSrc
agent.channels = accessLogsChannel
agent.sinks = kafkaSink

# For each one of the sources, the type is defined
agent.sources.accessLogsSrc.type = exec
agent.sources.accessLogsSrc.command = tail -F /var/log/httpd/access_log
#agent.sources.accessLogsSrc.batchSize = 20

# Each sink's type must be defined
agent.sinks.kafkaSink.type = com.thilinamb.flume.sink.KafkaSink
agent.sinks.kafkaSink.topic = access_logs
agent.sinks.kafkaSink.preprocessor = com.hortonworks.demo.AccessLogMessageProcessor
agent.sinks.kafkaSink.kafka.metadata.broker.list = bimota.hortonworks.local:6667
agent.sinks.kafkaSink.kafka.serializer.class = kafka.serializer.StringEncoder
agent.sinks.kafkaSink.kafka.request.required.acks = 1

# Each channel's type is defined.
agent.channels.accessLogsChannel.type = file
agent.channels.accessLogsChannel.checkpointDir = /opt/assemblies/log_management/state/flume/checkpoints
agent.channels.accessLogsChannel.dataDirs = /opt/assemblies/log_management/state/flume/data
agent.channels.accessLogsChannel.capacity = 1000000
agent.channels.accessLogsChannel.transactionCapacity = 1000000

#  Connect the source and sink via the channel
agent.sources.accessLogsSrc.channels = accessLogsChannel
agent.sinks.kafkaSink.channel = accessLogsChannel
